import streamlit as st
import pandas as pd
import shioaji as sj
import time
import datetime
from pathlib import Path
import sys

# Ensure current directory is in python path for imports
sys.path.append(str(Path(__file__).resolve().parent))

import config
import strategy
from line_notifier import notifier

# Page Configuration
st.set_page_config(page_title="å°è‚¡å³æ™‚å¼·å‹¢è·³ç©ºç¯©é¸", layout="wide")

# Helper Functions
@st.cache_resource(ttl=3600*4) # Cache for 4 hours, but validate logic will clear it if stale
def init_shioaji():
    try:
        api = sj.Shioaji(simulation=True) 
        # Attempt login
        if "api_key" in config.CONFIG and "secret_key" in config.CONFIG:
            api.login(
                api_key=config.CONFIG["api_key"], 
                secret_key=config.CONFIG["secret_key"]
            )
            
            
        # Validate Contracts (The Blocking Wait)
        has_contracts = False
        if hasattr(api, 'Contracts'):
             try:
                 if api.Contracts.Stocks["2330"]: has_contracts = True
             except: pass
             
        if not has_contracts:
            st.warning("âš ï¸ åµæ¸¬åˆ°åˆç´„åº«å°šæœªå°±ç·’ï¼Œæ­£åœ¨ä¸‹è¼‰æœ€æ–°åˆç´„... (è«‹å‹¿é—œé–‰)")
            try:
                api.fetch_contracts(contract_download=True)
                
                # Wait loop (Max 60s)
                progress_text = "ç­‰å¾…åˆç´„ä¸‹è¼‰ä¸­..."
                my_bar = st.progress(0, text=progress_text)
                
                for i in range(60):
                    time.sleep(1)
                    try:
                        if api.Contracts.Stocks["2330"]:
                            st.success("âœ… åˆç´„ä¸‹è¼‰èˆ‡è¼‰å…¥å®Œæˆ!")
                            my_bar.empty()
                            has_contracts = True
                            break
                    except:
                        pass
                    my_bar.progress(int((i/60)*100), text=f"{progress_text} ({i}s)")
                
                if not has_contracts:
                    st.error("âŒ åˆç´„ä¸‹è¼‰è¶…æ™‚ (60s)ï¼Œéƒ¨åˆ†åŠŸèƒ½å¯èƒ½ç„¡æ³•ä½¿ç”¨ã€‚è«‹æª¢æŸ¥ç¶²éš›ç¶²è·¯é€£ç·šã€‚")
                    
            except Exception as e:
                st.error(f"åˆç´„ä¸‹è¼‰æŒ‡ä»¤å¤±æ•—: {e}")

        return api
    except Exception as e:
        st.error(f"Shioaji Login Failed: {e}")
        return None

def get_valid_api():
    """Wrapper to get API and ensure it's actually alive and has contracts"""
    api = init_shioaji()
    if not api: return None
    
    # Strict Health Check: Must have Contracts loaded
    # Only checking '2330' as a proxy for "Contracts Loaded"
    is_healthy = False
    try:
        if api.Contracts.Stocks["2330"]: is_healthy = True
    except: pass
    
    if not is_healthy:
        st.warning("âš ï¸ åµæ¸¬åˆ° API å¿«ç…§å¤±æ•ˆ (åˆç´„åº«éºå¤±)ï¼Œæ­£åœ¨é‡ç½®é€£ç·š...")
        st.cache_resource.clear() # Clear the corrupted cache
        time.sleep(1)
        return init_shioaji() # Create fresh instance
        
    return api


def run_pre_process():
    import pre_process
    with st.spinner('åŸ·è¡Œç›¤å‰ç¯©é¸ä¸­ (FinLab)...'):
        stock_list = pre_process.get_candidates()
    st.success(f"ç¯©é¸å®Œæˆï¼å…± {len(stock_list)} æª”ä½åŸºæœŸè‚¡ç¥¨ã€‚")
    return stock_list

def fetch_snapshots_parallel(api, contracts, chunk_size=15, max_workers=2):
    """
    Fetches snapshots for a list of contracts using parallel threads.
    Handles chunking and retries automatically.
    """
    from concurrent.futures import ThreadPoolExecutor, as_completed
    
    # Split contracts into chunks
    chunks = [contracts[i:i+chunk_size] for i in range(0, len(contracts), chunk_size)]
    
    snapshots = []
    
    def fetch_chunk_with_retry(api, chunk, chunk_id):
        max_retries = 3
        for attempt in range(max_retries):
            try:
                # Shioaji api calls should be thread-safe for simple reads
                res = api.snapshots(chunk)
                if res: return res
            except Exception:
                # Silently retry or log if needed
                pass
        return []

    # Execute in Parallel
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(fetch_chunk_with_retry, api, c, i): i for i, c in enumerate(chunks)}
        
        for future in as_completed(futures):
            res = future.result()
            if res:
                snapshots.extend(res)
                
    return snapshots

# --- Main Logic with State ---
if 'monitoring' not in st.session_state:
    st.session_state.monitoring = False
if 'log' not in st.session_state:
    st.session_state.log = []
if 'active_df' not in st.session_state:
    st.session_state.active_df = pd.DataFrame(columns=["ä»£ç¢¼", "åç¨±", "ç¾åƒ¹", "è·³ç©º%", "P-Loc", "ä¹–é›¢ç‡", "é‡èƒ½", "ç‰¹å¾µ"])
if 'watchlist_df' not in st.session_state:
    st.session_state.watchlist_df = pd.DataFrame(columns=["ä»£ç¢¼", "åç¨±", "ç¾åƒ¹", "è·³ç©º%", "P-Loc", "ä¹–é›¢ç‡", "é‡èƒ½", "ç‰¹å¾µ"])
if 'gap_df' not in st.session_state:
    st.session_state.gap_df = pd.DataFrame(columns=["ä»£ç¢¼", "åç¨±", "ç¾åƒ¹", "è·³ç©º%", "P-Loc", "ä¹–é›¢ç‡", "é‡èƒ½", "ç‰¹å¾µ"])
if 'monitoring_list' not in st.session_state:
    st.session_state.monitoring_list = []
if 'discarded_count' not in st.session_state:
    st.session_state.discarded_count = 0
if 'retry_counts' not in st.session_state:
    st.session_state.retry_counts = {}  # Map: stock_code -> failure_count

st.title("ğŸš€ å°è‚¡å³æ™‚å¼·å‹¢è·³ç©ºç¯©é¸å™¨")

# Sidebar
with st.sidebar:
    with st.expander("ğŸ“– å°ˆæ¡ˆäº¤æ˜“æµç¨‹èªªæ˜"):
        st.markdown("""
        ### 1. ç›¤å‰æº–å‚™ (Pre-Market)
        *   **ç›®æ¨™**ï¼šç¯©é¸å‡ºã€Œä½åŸºæœŸã€çš„æ½›åŠ›è‚¡ã€‚
        *   **åŸ·è¡Œ**ï¼šè‹¥ç„¡åå–®ï¼ŒUI æç¤ºåŸ·è¡Œã€Œç›¤å‰é‹ç®—ã€ã€‚
        *   **é‚è¼¯**ï¼šå–ä¹–é›¢ç‡ (Bias) æœ€ä½ä¹‹å¾Œ 30%ã€‚
        *   **é—œéµ**ï¼šè¨˜éŒ„æ˜¨æ—¥æœ€é«˜åƒ¹ (PrevHigh) ä½œç‚ºè·³ç©ºåŸºæº–ã€‚

        ### 2. ç›¤ä¸­ç›£æ§ (Intra-Day)
        *   **åŸ·è¡Œ**ï¼šé»æ“Šã€Œé–‹å§‹ç›£æ§ (Start)ã€ã€‚
        *   **æ ¸å¿ƒé‚è¼¯** (æ¯ 60 ç§’æƒæ)ï¼š
            1.  **åš´æ ¼è·³ç©º**ï¼š(Low >= PrevHigh) & (Open > PrevHigh * 1.01)
            2.  **è‚¡åƒ¹ä½éš**ï¼šP-Loc > 0.5 (ç¶­æŒä¸­é«˜æª”)
            3.  **é‡èƒ½**ï¼šé‡ > 500 å¼µ & é‡‘é¡ > 1000 è¬
        *   **LINE é€šçŸ¥**ï¼šé¦–æ¬¡é€²å…¥å¼·å‹¢å€æ™‚ç™¼é€ã€‚

        ### 3. ç›¤å¾Œå›æ¸¬ (Post-Market)
        *   **åŸ·è¡Œ**ï¼šæ”¶ç›¤å¾Œ (13:30) é»æ“Šã€Œæ­·å²å›æ”¾ã€ã€‚
        *   **é‚è¼¯**ï¼šä½¿ç”¨ç•¶æ—¥ 1 åˆ† K ç·šé‡ç¾ç›¤ä¸­èµ°å‹¢ã€‚
        """)
        
    st.header("æ§åˆ¶å°")
    
    # Debug: Manual Cache Clear
    if st.button("ğŸ”§ æ¸…é™¤ API å¿«å– (Debug)"):
        st.cache_resource.clear()
        st.success("âœ… å¿«å–å·²æ¸…é™¤ï¼Œè«‹é‡æ–°åŸ·è¡Œç¯©é¸æˆ–ç›£æ§")
        st.rerun()
    
    # 1. Credentials Check
    if "line_channel_access_token" not in config.CONFIG or config.CONFIG["line_channel_access_token"] == "YOUR_CHANNEL_ACCESS_TOKEN":
        st.warning("âš ï¸ è«‹å…ˆè¨­å®š LINE Messaging API Token")
    
    # 2. Data Check
    if not config.CANDIDATE_LIST_PATH.exists():
        st.warning("âš ï¸ å°šæœªå»ºç«‹ç›£æ§æ¸…å–®")
        if st.button("åŸ·è¡Œç›¤å‰é‹ç®— (FinLab)"):
            run_pre_process()
            st.rerun()
    else:
        st.success("âœ… ç›£æ§æ¸…å–®å·²å°±ç·’")
        # Load list to show count
        try:
            df = pd.read_csv(config.CANDIDATE_LIST_PATH)
            msg = f"ç›£æ§æª”æ•¸: {len(df)}"
            
            if 'data_date' in df.columns:
                d_date = str(df['data_date'].iloc[0])
                msg += f" | è³‡æ–™æ—¥æœŸ: {d_date}"
                
                # Check freshness (simple check vs system today)
                # Note: System time might be different from Taiwan Market time, but usually matches in this context.
                today_str = datetime.datetime.now().strftime('%Y-%m-%d')
                if d_date != today_str:
                    st.warning(f"âš ï¸ è³‡æ–™æ—¥æœŸ ({d_date}) éä»Šæ—¥ ({today_str})ï¼Œè«‹ç¢ºèªæ˜¯å¦éœ€è¦é‡æ–°åŸ·è¡Œç›¤å‰é‹ç®—ã€‚")
                    if st.button("é‡æ–°åŸ·è¡Œç›¤å‰é‹ç®— (FinLab)", key="rerun_pre_process_warning"):
                        run_pre_process()
                        st.rerun()
                else:
                    st.success(f"âœ… è³‡æ–™æ—¥æœŸ: {d_date} (æœ€æ–°)")
                    # Optional: Allow force re-run even if up to date
                    # if st.button("å¼·åˆ¶é‡æ–°åŸ·è¡Œç›¤å‰é‹ç®—"):
                    #    run_pre_process()
                    #    st.rerun()
            
            st.info(msg)
        except Exception as e:
            st.error(f"è®€å–æ¸…å–®å¤±æ•—: {e}")
            pass

    st.divider()
    
    # 3. Gap Filter (New Workflow)
    if st.button("ğŸ” åŸ·è¡Œé–‹ç›¤è·³ç©ºç¯©é¸ (Gap > 1%)"):
        st.session_state.monitoring = False # Stop monitoring first
        
        # Force clear cache to ensure fresh API
        st.cache_resource.clear()
        
        status = st.status("ğŸš€ å•Ÿå‹•ç¯©é¸æµç¨‹...", expanded=True)
        try:
            # Step 1: Init API (Fresh instance)
            status.write("ğŸ”„ æ­£åœ¨åˆå§‹åŒ– API èˆ‡ç¢ºèªåˆç´„...")
            api = init_shioaji()
            
            if not api:
                status.update(label="âŒ API é€£ç·šå¤±æ•—", state="error")
            else:
                # Step 2: Load Candidates
                status.write("ğŸ“‚ è®€å–ç›£æ§æ¸…å–®...")
                candidates_df = pd.read_csv(config.CANDIDATE_LIST_PATH)
                all_codes = candidates_df['stock_code'].astype(str).str.strip().tolist()
                
                # Convert to Contracts
                status.write(f"ğŸ“œ è½‰æ›åˆç´„ç‰©ä»¶ (å…± {len(all_codes)} æª”)...")
                contracts = []
                contract_info = {} # Map: code -> {name, reference}
                for code in all_codes:
                    try:
                        # Try TSE first (ä¸Šå¸‚)
                        symbol = f"TSE{code}"
                        c = getattr(api.Contracts.Stocks.TSE, symbol, None)
                        if not c:
                            # Try OTC (ä¸Šæ«ƒ)
                            symbol = f"OTC{code}"
                            c = getattr(api.Contracts.Stocks.OTC, symbol, None)
                        
                        if c:
                            contracts.append(c)
                            contract_info[code] = {
                                "name": c.name,
                                "reference": float(c.reference) if c.reference else 0.0
                            }
                        else:
                            status.write(f"âš ï¸ æ‰¾ä¸åˆ° {code} çš„åˆç´„ (TSE/OTC éƒ½æŸ¥ç„¡)")
                    except (KeyError, AttributeError) as e:
                        status.write(f"âš ï¸ æŸ¥è©¢ {code} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                        continue
                
                if not contracts:
                    status.update(label="âŒ æ‰¾ä¸åˆ°ä»»ä½•åˆç´„ (è«‹æª¢æŸ¥ API åˆå§‹åŒ–)", state="error")
                else:
                    # Step 3: Fetch Snapshots
                    status.write(f"â˜ï¸ æ­£åœ¨æŠ“å–å€‹è‚¡å ±åƒ¹ (Snapshotsï¼Œå…± {len(contracts)} æª”)...")
                    snapshots = fetch_snapshots_parallel(api, contracts, chunk_size=300, max_workers=2)
                    
                    if not snapshots:
                        status.update(label="âš ï¸ å–å¾— 0 ç­†è¡Œæƒ…ï¼Œå¯èƒ½æ˜¯éç›¤ä¸­æ™‚é–“", state="error")
                    else:
                        status.write(f"âœ… æˆåŠŸå–å¾— {len(snapshots)} ç­†è¡Œæƒ…è³‡æ–™")
                        # Step 4: Filter Logic
                        status.write("âš¡ åŸ·è¡Œè·³ç©ºé‚è¼¯é‹ç®—...")
                        gap_list = []
                        gap_data = []
                        
                        for snap in snapshots:
                            code = snap.code
                            open_ = snap.open
                            
                            # Expert Optimization: Use Static Reference instead of calculated one
                            info = contract_info.get(code, {})
                            ref_price = info.get("reference", 0.0)
                            name = info.get("name", code)
                            
                            if ref_price > 0 and open_ > 0:
                                pct = (open_ - ref_price) / ref_price
                                if pct >= 0.01:
                                    gap_list.append(code)
                                    gap_data.append({
                                        "ä»£ç¢¼": code,
                                        "åç¨±": name,
                                        "é–‹ç›¤": open_,
                                        "æ˜¨æ”¶": ref_price,
                                        "æ¼²å¹…%": f"{pct*100:.2f}%"
                                    })
                        
                        # Step 5: Update
                        st.session_state.monitoring_list = gap_list
                        st.session_state.gap_df = pd.DataFrame(gap_data)
                        
                        status.update(label=f"âœ… ç¯©é¸å®Œæˆ! ç¬¦åˆ: {len(gap_list)} æª”", state="complete")
                        
                        if gap_list:
                            st.success(f"å·²æ›´æ–°ç›£æ§åå–®ï¼Œå…± {len(gap_list)} æª”ç¬¦åˆé–‹ç›¤è·³ç©º > 1%")
                            st.write(st.session_state.gap_df)
                        else:
                            st.warning("æ²’æœ‰è‚¡ç¥¨ç¬¦åˆé–‹ç›¤è·³ç©º > 1% æ¢ä»¶")

        except Exception as e:
             status.update(label=f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}", state="error")

    st.divider()
    
    # 4. Monitor Control
    if not st.session_state.monitoring:
        if st.button("é–‹å§‹ç›£æ§ (Start)", type="primary"):
            st.session_state.monitoring = True
            st.rerun()
    else:
        if st.button("åœæ­¢ç›£æ§ (Stop)"):
            st.session_state.monitoring = False
            st.rerun()
            
    st.divider()
    st.write("ç›®å‰ç‹€æ…‹:", "ğŸŸ¢ ç›£æ§ä¸­" if st.session_state.monitoring else "ğŸ”´ å·²åœæ­¢")
    
    st.divider()
    
    # 4. Simulation (After Market)
    st.header("æ­·å²å›æ”¾æ¨¡çµ„")
    now_time = datetime.datetime.now().time()
    close_time = datetime.time(13, 30)
    
    if now_time >= close_time:
        sim_limit = st.number_input("æ¸¬è©¦æª”æ•¸é™åˆ¶ (0=å…¨éƒ¨)", min_value=0, value=10, step=10)
        
        # Start/Stop Logic
        if st.session_state.get('sim_state', 'IDLE') == 'IDLE':
            if st.button("å•Ÿå‹•å›æ”¾æ¸¬è©¦ (Start)"):
                st.session_state.sim_state = 'RUNNING'
                st.session_state.simulation_limit = sim_limit
                st.session_state.monitoring = False
                st.rerun()
        else:
            if st.button("âš ï¸ çµæŸå›æ”¾ (Exit Simulation)", type="primary"):
                st.session_state.sim_state = 'IDLE'
                st.rerun()
    else:
        st.caption("âš ï¸ é ˆæ–¼æ”¶ç›¤å¾Œ (13:30) é–‹æ”¾")

# Main Area
if st.session_state.monitoring:
    # --- NON-BLOCKING LOOP SIMULATION ---
    # We run ONE iteration then use st.rerun() after sleep?
    # No, that refreshes the whole page.
    # Better: A while loop inside a st.empty container?
    
    placeholder = st.empty()
    log_placeholder = st.empty()
    
    # Initialize API with Health Check
    api = get_valid_api()
    
    if not api:
        st.error("API åˆå§‹åŒ–å¤±æ•—ï¼Œè«‹æª¢æŸ¥ login.json")
        st.session_state.monitoring = False
    else:
        st.write("ğŸ”„ Step 1: é–‹å§‹æ–°ä¸€è¼ªç›£æ§æƒæ...")
        # Load Candidates
        # To strictly implement "Low > PrevHigh", we need PrevHigh data.
        # I'll update Pre-process logic later. For now, logic:
        # Load candidate list
        try:
            candidates_df = pd.read_csv(config.CANDIDATE_LIST_PATH)
            stock_codes = candidates_df['stock_code'].astype(str).str.strip().tolist()
            
            # Map bias and prev_high
            # candidates_df columns: stock_code, bias, prev_high
            bias_map_val = dict(zip(candidates_df['stock_code'].astype(str), candidates_df['bias']))
            
            if 'prev_high' in candidates_df.columns:
                prev_high_map = dict(zip(candidates_df['stock_code'].astype(str), candidates_df['prev_high']))
            else:
                st.warning("âš ï¸ ç›£æ§æ¸…å–®ç¼ºå°‘ 'prev_high' æ¬„ä½ï¼Œè«‹é‡æ–°åŸ·è¡Œç›¤å‰é‹ç®—ã€‚ç›®å‰æš«ç”¨æ˜¨æ”¶ä»£æ›¿ã€‚")
                prev_high_map = {}

            # --- FETCH SNAPSHOT (MOCKING REAL DATA FOR NOW IF MARKET CLOSED) ---
            # If simulation=True, api.snapshots might return mock or nothing depending on time.
            
            # Load candidate list if monitoring list is not set (First Run)
            if not st.session_state.monitoring_list or len(st.session_state.monitoring_list) == 0:
                st.session_state.monitoring_list = stock_codes 
            
            # Ensure current_monitor_codes is defined every run
            current_monitor_codes = st.session_state.monitoring_list
            st.write(f"âœ… Step 1 å®Œæˆ: è¼‰å…¥ç›£æ§åå–®å…± {len(current_monitor_codes)} æª”")

            contracts = []
            pending_removal = []

            # Reset discarded count if clean start
            if 'discarded_count' not in st.session_state:
                st.session_state.discarded_count = 0
            if 'retry_counts' not in st.session_state:
                st.session_state.retry_counts = {}
                
            # Filter out those already discarded or invalid contracts (though list is codes)
            
            # Dynamic Batching of REMAINING targets

                
                # Build Contracts Object List
                contract_info = {} # Map: code -> {name, reference}
                for code in current_monitor_codes:
                     try:
                         # Try TSE first (ä¸Šå¸‚)
                         symbol = f"TSE{code}"
                         c = getattr(api.Contracts.Stocks.TSE, symbol, None)
                         if not c:
                             # Try OTC (ä¸Šæ«ƒ)
                             symbol = f"OTC{code}"
                             c = getattr(api.Contracts.Stocks.OTC, symbol, None)
                         
                         if c:
                             contracts.append(c)
                             contract_info[code] = {
                                 "name": c.name,
                                 "reference": float(c.reference) if c.reference else 0.0
                             }
                     except (KeyError, AttributeError) as e:
                         continue
                
            st.write(f"âœ… Step 2 å®Œæˆ: æˆåŠŸå–å¾— Contract ç‰©ä»¶å…± {len(contracts)} ç­†")
            
            # DEBUG: Check if we have contracts
            if len(contracts) == 0:
                 st.error(f"âŒ åš´é‡éŒ¯èª¤: æ‰¾ä¸åˆ°ä»»ä½• Contract ç‰©ä»¶! (ç›£æ§æ¸…å–®: {len(current_monitor_codes)} ç­†)")
                 
                 # Detailed Diagnostics
                 st.write("--- è¨ºæ–·è³‡è¨Š ---")
                 try:
                     st.write(f"API Connected: {api.list_accounts()}")
                     tse_check = api.Contracts.Stocks['2330']
                     st.write(f"TSE Check (2330): {'âœ… Found' if tse_check else 'âŒ Not Found'}")
                     otc_check = api.Contracts.Stocks['8069']
                     st.write(f"OTC Check (8069): {'âœ… Found' if otc_check else 'âŒ Not Found'}")
                     
                     st.write(f"Total Stocks in API: {len([x for x in api.Contracts.Stocks])}")
                 except Exception as e:
                     st.write(f"Diagnostics Failed: {e}")
                 
                 st.info("ğŸ’¡ è«‹å˜—è©¦é‡æ–°æ•´ç†ç¶²é  (F5) ä»¥é‡æ–°è§¸ç™¼ init_shioaji åˆç´„ä¸‹è¼‰æµç¨‹ã€‚")
            
            # Use new parallel fetch helper (High Performance Mode)
            st.write("ğŸ”„ Step 3: æ­£åœ¨å‘ API è«‹æ±‚è¡Œæƒ… (Snapshots)...")
            snapshots = fetch_snapshots_parallel(api, contracts, chunk_size=300, max_workers=2)
            st.write(f"âœ… Step 3 å®Œæˆ: API å›å‚³ {len(snapshots)} ç­†è¡Œæƒ…è³‡æ–™")

                
            # --- PROCESS & FILTER ---
            kept_codes = []
            
            if len(snapshots) == 0:
                st.warning(f"âš ï¸ è­¦å‘Š: å–å¾— 0 ç­†è¡Œæƒ…è³‡æ–™ (é æœŸ: {len(contracts)} ç­†)")
            else:
                # DEBUG: Show first returned item data
                chk = snapshots[0]
                st.info(f"ğŸ” DEBUG Data Validation: Code={chk.code} | Open={chk.open} | Close={chk.close} | Vol={chk.total_volume} | Time={datetime.datetime.now().strftime('%H:%M:%S')}")

                for snap in snapshots:
                     code = snap.code
                     
                     # Expert Optimization: Use Static Reference instead of calculated one
                     info = contract_info.get(code, {})
                     ref_price = info.get("reference", 0.0)
                     name = info.get("name", code)
                     
                     close = snap.close
                     open_ = snap.open
                     high = snap.high
                     low = snap.low
                     vol = snap.total_volume
                     amt = snap.total_amount
                     
                     if close == 0: 
                         # No data yet? Keep it safe.
                         kept_codes.append(code)
                         continue

                     # Expert Advice: Use Static Reference when available
                     # Using prev_high from candidate list as the primary threshold
                     # But we'll also keep prev_close as a secondary reference
                     prev_close = ref_price if ref_price > 0 else (close - (snap.change_price or 0))
                     prev_high = prev_high_map.get(code, prev_close)
                     bias_val = bias_map_val.get(code, 0)
                     
                     # --- FILTERING LOGIC (Open-Gap) ---
                     # Rule: IF Volume > 0 (Opened), MUST meet Gap Condition.
                     # Gap Cond: Open > PrevHigh * 1.01 (User said "Gap")
                     # Actually user requirement: "base_gap = (low > prev_high) & (open_ > prev_high * 1.01)"
                     # Wait, Low isn't set at very first tick usually or equal to Open.
                     # Let's use strict GAP check on OPEN price first.
                     
                     # DEBUG TRACE specific stock
                     if code == '8048':
                         print(f"DEBUG[8048]: Open={open_}, PrevHigh={prev_high}, Threshold={prev_high*1.01}, Vol={vol}")

                     
                     if vol > 0:
                         # Has opened
                         is_gap = (open_ > prev_high * 1.01)
                         
                         if not is_gap:
                             # Sanity Check: Ensure valid Open price
                             if open_ <= 0:
                                 # Bad data (0), treat as not opened yet or error, do not increment retry
                                 kept_codes.append(code)
                                 continue

                             # Retry Mechanism (Double Confirmation)
                             # If gap condition fails, increment failure count. Only discard after N failures.
                             fail_count = st.session_state.retry_counts.get(code, 0) + 1
                             st.session_state.retry_counts[code] = fail_count
                             
                             if fail_count >= 3:
                                 # 3 strikes, you're out
                                 pending_removal.append(code)
                                 # Cleanup retry dict to save mem? Optional.
                             else:
                                 # Give another chance
                                 kept_codes.append(code)
                             
                             continue # Skip further processing for this tick
                         else:
                             # Keep
                             kept_codes.append(code)
                     else:
                         # Not opened yet, keep waiting
                         kept_codes.append(code)
                         continue # No price to analyze yet
                     
                     # If we are here, it is a GAP stock (or pre-open check passed?)
                     # Proceed to 'Active' Check
                     
                     # Call Shared Logic
                     is_active, features, p_loc, cond_gap = strategy.check_criteria(snap, prev_high, bias_val)
                     
                     row = {
                        "æ™‚é–“": datetime.datetime.now().strftime("%H:%M:%S"),
                        "ä»£ç¢¼": code,
                        "åç¨±": name,
                        "ç¾åƒ¹": close,
                        "è·³ç©º%": f"{((open_ - prev_close)/prev_close)*100:.2f}%",
                        "P-Loc": f"{p_loc:.2f}",
                        "ä¹–é›¢ç‡": f"{bias_val:.2%}",
                        "é‡èƒ½": f"{vol}å¼µ",
                        "ç‰¹å¾µ": " ".join(features)
                     }
                     
                     if is_active:
                         active_data.append(row)
                         notifier.notify_signal(code, name, close, (open_ - prev_close)/prev_close, p_loc, vol, amt)
                         if 'triggered_history' not in st.session_state:
                             st.session_state.triggered_history = set()
                         st.session_state.triggered_history.add(code)
                         
                     elif 'triggered_history' in st.session_state and code in st.session_state.triggered_history:
                         if not features: row['ç‰¹å¾µ'] = "(è½‰å¼±è§€å¯Ÿ)"
                         watchlist_data.append(row)
                     
                     if cond_gap:
                         gap_candidates_data.append(row)

                # UPDATE STATE LIST
                # Actually we constructed 'kept_codes' but we iterate snapshots which might be partial if error?
                # Safer: Remove 'pending_removal' from session_state list
                if pending_removal:
                    st.session_state.discarded_count += len(pending_removal)
                    st.session_state.monitoring_list = [c for c in st.session_state.monitoring_list if c not in pending_removal]
                    # st.toast(f"å·²å‰”é™¤ {len(pending_removal)} æª”ç„¡è·³ç©ºå€‹è‚¡")

                # Update Display Frames
                if active_data:
                    st.session_state.active_df = pd.DataFrame(active_data)
                else:
                    st.session_state.active_df = pd.DataFrame(columns=["ä»£ç¢¼", "åç¨±", "ç¾åƒ¹", "è·³ç©º%", "P-Loc", "ä¹–é›¢ç‡", "é‡èƒ½", "ç‰¹å¾µ"])
                    
                if watchlist_data:
                    st.session_state.watchlist_df = pd.DataFrame(watchlist_data)
                else:
                    st.session_state.watchlist_df = pd.DataFrame(columns=["ä»£ç¢¼", "åç¨±", "ç¾åƒ¹", "è·³ç©º%", "P-Loc", "ä¹–é›¢ç‡", "é‡èƒ½", "ç‰¹å¾µ"])
                
                if gap_candidates_data:
                     st.session_state.gap_df = pd.DataFrame(gap_candidates_data)
                else:
                     st.session_state.gap_df = pd.DataFrame(columns=["ä»£ç¢¼", "åç¨±", "ç¾åƒ¹", "è·³ç©º%", "P-Loc", "ä¹–é›¢ç‡", "é‡èƒ½", "ç‰¹å¾µ"])
            
            # Display
            # Split View
            placeholder.empty() # Clear previous
            with placeholder.container():
                # Status Banner
                st.info(f"ğŸ“Š ç›£æ§ç‹€æ…‹: å‰©é¤˜ {len(st.session_state.monitoring_list)} æª” | å·²éæ¿¾å‰”é™¤ {st.session_state.discarded_count} æª”")
                
                st.subheader("ğŸ”¥ ç›®å‰å¼·å‹¢å€ (Active Matches)")
                st.dataframe(st.session_state.active_df, use_container_width=True)
                
                st.divider()
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.subheader("ğŸ‘€ è½‰å¼±è§€å¯Ÿå€ (Watchlist)")
                    st.caption("æ›¾ç¶“ç¬¦åˆæ¢ä»¶ï¼Œç›®å‰æš«æ™‚è½‰å¼±ä¹‹æ¨™çš„")
                    st.dataframe(st.session_state.watchlist_df, use_container_width=True)
                
                with col2:
                    st.subheader("ğŸªœ ç¬¦åˆè·³ç©º (Gap Candidates)")
                    st.caption("é–‹ç›¤è·³ç©º > 1% (å¯èƒ½å› é‡èƒ½/ä½éšæœªå…¥é¸)")
                    st.dataframe(st.session_state.gap_df, use_container_width=True)
                
            st.success(f"æœ€è¿‘ä¸€æ¬¡æ›´æ–°: {datetime.datetime.now().strftime('%H:%M:%S')}")
            
            # Loop delay
            time.sleep(60) 
            st.rerun()

        except Exception as e:
            st.error(f"ç›£æ§åŸ·è¡ŒéŒ¯èª¤: {e}")
            st.session_state.monitoring = False

else:
    st.info("è«‹é»æ“Šå·¦å´ã€Œé–‹å§‹ç›£æ§ã€æŒ‰éˆ•")
    if 'active_df' in st.session_state and not st.session_state.active_df.empty:
        st.write("ğŸ“ æ´»èºä¸­ (Active):")
        st.dataframe(st.session_state.active_df)
    if 'watchlist_df' in st.session_state and not st.session_state.watchlist_df.empty:
        st.write("ğŸ‘€ è§€å¯Ÿä¸­ (Watchlist):")
        st.dataframe(st.session_state.watchlist_df)
    if 'gap_df' in st.session_state and not st.session_state.gap_df.empty:
        st.write("ğŸªœ ç¬¦åˆè·³ç©º (Gap Candidates):")
        st.dataframe(st.session_state.gap_df)

# --- Simulation Logic ---
# State Machine: IDLE -> RUNNING -> FINISHED -> IDLE

if 'sim_state' not in st.session_state:
    st.session_state.sim_state = 'IDLE'

# Check Sidebar Start (Update logic up there or handle purely by state)
# We need to rely on the sidebar button setting the state to RUNNING.

if st.session_state.sim_state == 'RUNNING':
    st.info("ğŸ”µ æ­£åœ¨åŸ·è¡Œæ­·å²å›æ”¾æ¨¡å¼...")
    
    # Containers
    status_text = st.empty()
    progress_bar = st.progress(0)
    sim_table = st.empty()
    
    # Init API
    api = init_shioaji()
    
    try:
        candidates_df = pd.read_csv(config.CANDIDATE_LIST_PATH)
        
        # Containers for Split View
        st.subheader("ğŸ”¥ æ¨¡æ“¬-ç›®å‰å¼·å‹¢å€")
        active_table = st.empty()
        
        st.divider()
        
        st.subheader("ğŸ‘€ æ¨¡æ“¬-è½‰å¼±è§€å¯Ÿå€")
        watchlist_table = st.empty()
        
        def on_status_update(msg):
            status_text.write(msg)
            
        def on_match_found(active_list, watchlist_list):
            # Update Tables
            if active_list:
                active_table.dataframe(pd.DataFrame(active_list))
            else:
                active_table.dataframe(pd.DataFrame(columns=["æ™‚é–“", "ä»£ç¢¼", "åç¨±", "ç¾åƒ¹", "è·³ç©º%", "P-Loc", "ä¹–é›¢ç‡", "é‡èƒ½", "ç‰¹å¾µ"]))
                
            if watchlist_list:
                watchlist_table.dataframe(pd.DataFrame(watchlist_list))
            else:
                watchlist_table.dataframe(pd.DataFrame(columns=["æ™‚é–“", "ä»£ç¢¼", "åç¨±", "ç¾åƒ¹", "è·³ç©º%", "P-Loc", "ä¹–é›¢ç‡", "é‡èƒ½", "ç‰¹å¾µ"]))
            
        import simulation_runner
        
        limit_val = st.session_state.get('simulation_limit', 10)
        
        simulation_runner.run_simulation_for_ui(
            api, 
            candidates_df, 
            status_callback=on_status_update,
            match_callback=on_match_found,
            progress_bar=progress_bar,
            limit=limit_val
        )
        
        # Transition to finished (keep last state)
        st.session_state.sim_state = 'FINISHED'
        # We don't save full snapshot history to state for simplicity, just IDLE logic
        # OR we could save the last frame if we want to show it in FINISHED state.
        # But 'FINISHED' state just shows "Sim Complete". 
        # Actually user wants to see the FINAL state.
        st.rerun()
        
    except Exception as e:
        st.error(f"æ¨¡æ“¬å¤±æ•—: {e}")
        if st.button("è¿”å›"):
            st.session_state.sim_state = 'IDLE'
            st.rerun()

elif st.session_state.sim_state == 'FINISHED':
    st.success("æ¨¡æ“¬åŸ·è¡Œå®Œç•¢ï¼(è«‹çœ‹ä¸Šæ–¹æœ€å¾Œç‹€æ…‹)")
    
    if st.button("é€€å‡ºæ¨¡æ“¬æ¨¡å¼ (Exit)"):
        st.session_state.sim_state = 'IDLE'
        st.session_state.monitoring = False 
        st.rerun()
